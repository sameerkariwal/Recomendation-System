{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content-Based Filtering model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loading required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from C:\\users\\SumitJain\\Documents\\upgd\\recommendation_system\\modules\\data_processing.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SumitJain\\Documents\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of users: 1895\n",
      "no. of users with atleast 5 consumptions: 1140\n",
      "no. of interactions: 72312\n",
      "no. of interactions from users with at least 5 engagement: 69868\n",
      "no. of unique user/item interactions: 39106\n",
      "engagement in train set: 33240\n",
      "engagement in on test set: 5866\n",
      "               consumer_id              item_id  type_weightage\n",
      "2103  -8550167523008133722  -454649054276160610        1.000000\n",
      "31618  4670267857749552625  6587635730509289343        1.000000\n",
      "18745  -444330148331768170 -1297580205670251233        2.000000\n",
      "34490  6686431125336194142 -4994468824009200256        1.000000\n",
      "27398  3576137684812235192 -5570129644089964821        1.000000\n",
      "...                    ...                  ...             ...\n",
      "20971   692689608292948411  2435024834845042614        2.321928\n",
      "23030  1623838599684589103 -5781461435447152359        1.000000\n",
      "24932  2416280733544962613  7400903238402587728        1.584963\n",
      "31680  4778050608932092852  1642787330067525131        2.000000\n",
      "29484  3829784524040647339  7273139206342584600        1.000000\n",
      "\n",
      "[33240 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import sklearn\n",
    "import import_ipynb\n",
    "sys.path.append(os.path.abspath(os.path.join('__file__','../../')))\n",
    "from modules import evaluations \n",
    "from modules import data_processing\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from config.configs import MODEL_CONTENT\n",
    "# from data_processing import reading_content_data,train_test_user_behaviour, plat_articles, model_evaluator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### since it's importing data processing code, it'll run and display the required inside it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loading data from data processing code and preparing model input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "engagement in train set: 33240\n",
      "engagement in on test set: 5866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SumitJain\\Documents\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3249: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "plat_articles,user_behaviour_df = data_processing.reading_content_data()\n",
    "user_behaviour_train_df = data_processing.train_test_user_behaviour()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ignoring stopwords (words with no semantics) from English and Portuguese (as we have a corpus with mixed languages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('english') + stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a model with vectors size 5000 (i.e.top max_features ordered by term frequency across the corpus),ignoring terms having a document frequency strictly lower than the given threshold min_df composed by the main unigrams and bigrams found in the corpus, ignoring stopwords\n",
    "\n",
    "#### instantiating model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
      "                input='content', lowercase=True, max_df=0.5, max_features=5000,\n",
      "                min_df=0.003, ngram_range=(1, 2), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True,\n",
      "                stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
      "                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
      "                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
      "                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
      "                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
      "                            'itself', ...],\n",
      "                strip_accents=None, sublinear_tf=False,\n",
      "                token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "                vocabulary=None)\n",
      "['00', '000', '04', '05', '10', '10 000', '10 years', '100', '100 000', '11', '12', '13', '14', '15', '150', '16', '17', '18', '19', '20', '200', '2000', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015', '2016', '2017', '2020', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '300', '31', '32', '33', '34', '35', '360', '37', '3d', '40', '400', '42', '45', '48', '49', '50', '500', '52', '53', '55', '60', '64', '70', '75', '80', '800', '85', '90', '95', '99', 'abaixo', 'aberta', 'aberto', 'abertura', 'ability', 'able', 'abordagem', 'abril', 'abrir', 'absolutely', 'abstract', 'abstraction', 'acaba', 'academic', 'accelerate', 'accelerated', 'accenture', 'accept', 'acceptance', 'accepted', 'access', 'accessibility', 'accessible', 'accomplish', 'according', 'accordingly', 'account', 'accounts', 'accuracy', 'accurate', 'accurately', 'acessar', 'acesso', 'achieve', 'achieved', 'achieving', 'acima', 'acontece', 'acontecer', 'acordo', 'acquia', 'acquire', 'acquired', 'acquisition', 'across', 'across multiple', 'act', 'action', 'actionable', 'actions', 'active', 'actively', 'activities', 'activity', 'acts', 'actual', 'actually', 'ad', 'adapt', 'adapter', 'add', 'added', 'adding', 'addition', 'additional', 'additionally', 'address', 'addresses', 'adds', 'adicionar', 'adjust', 'admin', 'administração', 'adobe', 'adopt', 'adopted', 'adopting', 'adoption', 'ads', 'advance', 'advanced', 'advances', 'advantage', 'advantages', 'advertising', 'advice', 'adwords', 'affect', 'affected', 'afinal', 'afirma', 'age', 'agencies', 'agency', 'agenda', 'agent', 'agents', 'aggregate', 'aggregation', 'aggregations', 'agile', 'agility', 'ago', 'agora', 'agree', 'agreed', 'agricultura', 'agriculture', 'agência', 'agências', 'ahead', 'ai', 'aim', 'aimed', 'aims', 'ainda', 'air', 'airbnb', 'airport', 'ajuda', 'ajudar', 'alcançar', 'alerts', 'alex', 'alexa', 'algo']\n"
     ]
    }
   ],
   "source": [
    "# model class\n",
    "vectorizer = TfidfVectorizer(analyzer='word',min_df=0.003,max_df=0.5,max_features=5000,ngram_range=(1, 2),stop_words=stopwords_list)\n",
    "print(vectorizer)\n",
    "\n",
    "item_ids = plat_articles['item_id'].tolist()\n",
    "tfidf_matrix = vectorizer.fit_transform(plat_articles['title'] + \"\" + plat_articles['text_description'])\n",
    "tfidf_feature_names = vectorizer.get_feature_names()\n",
    "# tfidf_matrix\n",
    "print(tfidf_feature_names[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix[10:13].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating user-item profiling for usage in model downstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_item_profiles(all_item_ids):\n",
    "    \n",
    "    item_profiles_list = [tfidf_matrix[item_ids.index(x):item_ids.index(x)+1] for x in all_item_ids]\n",
    "    item_profiles = scipy.sparse.vstack(item_profiles_list)\n",
    "    return item_profiles\n",
    "\n",
    "\n",
    "def generate_users_profiles():\n",
    "    \n",
    "    user_behaviour_indexed_df = user_behaviour_train_df[user_behaviour_train_df['item_id'] \\\n",
    "                                                   .isin(plat_articles['item_id'])].set_index('consumer_id')\n",
    "    user_profiles = {}\n",
    "    for person_id in user_behaviour_indexed_df.index.unique():\n",
    "        \n",
    "        user_behaviour_person_df = user_behaviour_indexed_df.loc[person_id]\n",
    "        user_item_profiles = create_item_profiles(user_behaviour_person_df['item_id'])\n",
    "        user_item_strengths = np.array(user_behaviour_person_df['type_weightage']).reshape(-1,1)\n",
    "        # Weighted average of item profiles by the user_behaviour strength\n",
    "        user_item_strengths_weighted_avg = np.sum(user_item_profiles.multiply(user_item_strengths), axis=0) / np.sum(user_item_strengths)\n",
    "        user_profile_normalized = sklearn.preprocessing.normalize(user_item_strengths_weighted_avg)\n",
    "        \n",
    "        user_profiles[person_id] = user_profile_normalized\n",
    "        \n",
    "    return user_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00086558 0.01448108 0.00048647 ... 0.         0.00441459 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "user_profiles = generate_users_profiles()\n",
    "len(user_profiles)\n",
    "\n",
    "print(user_profiles[-1479311724257856983])#.flatten().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### getting token of the corpus and it's relevance score in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5000)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>learning</td>\n",
       "      <td>0.294515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>machine learning</td>\n",
       "      <td>0.254875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>machine</td>\n",
       "      <td>0.244676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>google</td>\n",
       "      <td>0.222147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>data</td>\n",
       "      <td>0.159726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>ai</td>\n",
       "      <td>0.140805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>graph</td>\n",
       "      <td>0.116348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>like</td>\n",
       "      <td>0.107846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>language</td>\n",
       "      <td>0.086821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>algorithms</td>\n",
       "      <td>0.085046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>people</td>\n",
       "      <td>0.078480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>apple</td>\n",
       "      <td>0.077804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>human</td>\n",
       "      <td>0.077270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>0.075919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>use</td>\n",
       "      <td>0.074506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>research</td>\n",
       "      <td>0.074167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>company</td>\n",
       "      <td>0.074003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>deep learning</td>\n",
       "      <td>0.073349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>deep</td>\n",
       "      <td>0.072409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>models</td>\n",
       "      <td>0.071145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               token  relevance\n",
       "0           learning   0.294515\n",
       "1   machine learning   0.254875\n",
       "2            machine   0.244676\n",
       "3             google   0.222147\n",
       "4               data   0.159726\n",
       "5                 ai   0.140805\n",
       "6              graph   0.116348\n",
       "7               like   0.107846\n",
       "8           language   0.086821\n",
       "9         algorithms   0.085046\n",
       "10            people   0.078480\n",
       "11             apple   0.077804\n",
       "12             human   0.077270\n",
       "13      intelligence   0.075919\n",
       "14               use   0.074506\n",
       "15          research   0.074167\n",
       "16           company   0.074003\n",
       "17     deep learning   0.073349\n",
       "18              deep   0.072409\n",
       "19            models   0.071145"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myprofile = user_profiles[-1479311724257856983]\n",
    "print(myprofile.shape)\n",
    "pd.DataFrame(sorted(zip(tfidf_feature_names, \n",
    "                        user_profiles[-1479311724257856983].flatten().tolist()), key=lambda x: -x[1])[:20],\n",
    "             columns=['token', 'relevance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating content based model with all the above functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentFiltering:\n",
    "    \n",
    "    \n",
    "    def __init__(self, items_df=None):\n",
    "        self.item_ids = item_ids\n",
    "        self.items_df = items_df\n",
    "        \n",
    "    def compute_user_item_profile_similarity(self, person_id, topn=1000):\n",
    "        #Computes the cosine similarity between the user profile and all item profiles\n",
    "        cosine_similarities = cosine_similarity(user_profiles[person_id], tfidf_matrix)\n",
    "#         print(\"cosine_similarities\",cosine_similarities)\n",
    "        #Gets the top similar items\n",
    "        similar_indices = cosine_similarities.argsort().flatten()[-topn:]\n",
    "        #Sort the similar items by similarity\n",
    "        similar_items = sorted([(item_ids[i], cosine_similarities[0,i]) for i in similar_indices], key=lambda x: -x[1])\n",
    "        return similar_items\n",
    "        \n",
    "    def get_item_recommendations(self, user_id, items_to_ignore=[], topn=10, verbose=False):\n",
    "        similar_items = self.compute_user_item_profile_similarity(user_id)\n",
    "        #Ignores items the user has already interacted\n",
    "        similar_items_filtered = list(filter(lambda x: x[0] not in items_to_ignore, similar_items))\n",
    "        \n",
    "        recommendations_df = pd.DataFrame(similar_items_filtered, columns=['item_id', 'sim_score']) \\\n",
    "                                    .head(topn)\n",
    "\n",
    "        if verbose:\n",
    "            if self.items_df is None:\n",
    "                raise Exception('\"items_df\" is required in verbose mode')\n",
    "\n",
    "            recommendations_df = recommendations_df.merge(self.items_df, how = 'left', \n",
    "                                                          left_on = 'item_id', \n",
    "                                                          right_on = 'item_id')[['sim_score', 'item_id', 'title', 'item_url', 'language']]\n",
    "\n",
    "        return recommendations_df\n",
    "    \n",
    "content_based_recommender_model = ContentFiltering(plat_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predicting content by generating similar content as recommendation, showing top 10 for the queried item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content based recommendations: \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>sim_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5250363310227021277</td>\n",
       "      <td>0.686770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-7126520323752764957</td>\n",
       "      <td>0.684897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>638282658987724754</td>\n",
       "      <td>0.613627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5258604889412591249</td>\n",
       "      <td>0.584799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-8068727428160395745</td>\n",
       "      <td>0.574765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>-229081393244987789</td>\n",
       "      <td>0.561792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>-9033211547111606164</td>\n",
       "      <td>0.557539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2220561310072186802</td>\n",
       "      <td>0.554116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>54678605145828343</td>\n",
       "      <td>0.553812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>-4571929941432664145</td>\n",
       "      <td>0.552499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               item_id  sim_score\n",
       "0  5250363310227021277   0.686770\n",
       "1 -7126520323752764957   0.684897\n",
       "2   638282658987724754   0.613627\n",
       "3  5258604889412591249   0.584799\n",
       "4 -8068727428160395745   0.574765\n",
       "5  -229081393244987789   0.561792\n",
       "6 -9033211547111606164   0.557539\n",
       "7  2220561310072186802   0.554116\n",
       "8    54678605145828343   0.553812\n",
       "9 -4571929941432664145   0.552499"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"content based recommendations: \\n\\n\")\n",
    "content_based_recommender_model.get_item_recommendations(-1479311724257856983)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### evaluating the tfidf content based filtering model performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "974 users processed\n",
      "     hitrate@5_count  hitrate@10_count  interacted_count  recallscore@5  \\\n",
      "54                19                30               168       0.113095   \n",
      "40                13                21               119       0.109244   \n",
      "31                16                20               105       0.152381   \n",
      "52                25                40                86       0.290698   \n",
      "76                 5                 9                62       0.080645   \n",
      "..               ...               ...               ...            ...   \n",
      "355                0                 0                 1       0.000000   \n",
      "786                0                 0                 1       0.000000   \n",
      "787                0                 0                 1       0.000000   \n",
      "788                0                 0                 1       0.000000   \n",
      "974                0                 0                 1       0.000000   \n",
      "\n",
      "     recallscore@10            person_id  \n",
      "54         0.178571  3609194402293569455  \n",
      "40         0.176471 -2626634673110551643  \n",
      "31         0.190476 -1032019229384696495  \n",
      "52         0.465116 -1443636648652872475  \n",
      "76         0.145161  1116121227607581999  \n",
      "..              ...                  ...  \n",
      "355        0.000000 -6246099423021213661  \n",
      "786        0.000000   998688566268269815  \n",
      "787        0.000000   490109768671667408  \n",
      "788        0.000000   148641288870400064  \n",
      "974        0.000000  1492042537097239970  \n",
      "\n",
      "[975 rows x 6 columns]\n",
      "overall metrics:\n",
      " {'model_type': 'content_based', 'recallscore@5': 0.17695192635526763, 'recallscore@10': 0.2664507330378452}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hitrate@5_count</th>\n",
       "      <th>hitrate@10_count</th>\n",
       "      <th>interacted_count</th>\n",
       "      <th>recallscore@5</th>\n",
       "      <th>recallscore@10</th>\n",
       "      <th>person_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>168</td>\n",
       "      <td>0.113095</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>3609194402293569455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>119</td>\n",
       "      <td>0.109244</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>-2626634673110551643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>105</td>\n",
       "      <td>0.152381</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>-1032019229384696495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>25</td>\n",
       "      <td>40</td>\n",
       "      <td>86</td>\n",
       "      <td>0.290698</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>-1443636648652872475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>62</td>\n",
       "      <td>0.080645</td>\n",
       "      <td>0.145161</td>\n",
       "      <td>1116121227607581999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>60</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>-9016528795238256703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>58</td>\n",
       "      <td>0.189655</td>\n",
       "      <td>0.258621</td>\n",
       "      <td>692689608292948411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>55</td>\n",
       "      <td>0.072727</td>\n",
       "      <td>0.109091</td>\n",
       "      <td>-2979881261169775358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>234</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>0.169811</td>\n",
       "      <td>3636910968448833585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.134615</td>\n",
       "      <td>1623838599684589103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     hitrate@5_count  hitrate@10_count  interacted_count  recallscore@5  \\\n",
       "54                19                30               168       0.113095   \n",
       "40                13                21               119       0.109244   \n",
       "31                16                20               105       0.152381   \n",
       "52                25                40                86       0.290698   \n",
       "76                 5                 9                62       0.080645   \n",
       "34                 6                11                60       0.100000   \n",
       "6                 11                15                58       0.189655   \n",
       "103                4                 6                55       0.072727   \n",
       "234                4                 9                53       0.075472   \n",
       "123                3                 7                52       0.057692   \n",
       "\n",
       "     recallscore@10            person_id  \n",
       "54         0.178571  3609194402293569455  \n",
       "40         0.176471 -2626634673110551643  \n",
       "31         0.190476 -1032019229384696495  \n",
       "52         0.465116 -1443636648652872475  \n",
       "76         0.145161  1116121227607581999  \n",
       "34         0.183333 -9016528795238256703  \n",
       "6          0.258621   692689608292948411  \n",
       "103        0.109091 -2979881261169775358  \n",
       "234        0.169811  3636910968448833585  \n",
       "123        0.134615  1623838599684589103  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_overall_metrics, content_eval_results_df = evaluations.model_evaluator.evaluate_model(content_based_recommender_model,MODEL_CONTENT)\n",
    "print('overall metrics:\\n', content_overall_metrics)\n",
    "content_eval_results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
